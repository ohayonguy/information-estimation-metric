{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from information_estimation_metric import InformationEstimationMetric\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import resize\n",
    "import torch\n",
    "import math\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05c94241-5c7c-4f9d-bd9a-23685856e43b",
   "metadata": {},
   "source": [
    "iem = InformationEstimationMetric('./checkpoints/imagenet_256x256_loguniform_00400000.pth', 'bf16', False).cuda()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "70614900-df72-4451-8bd7-5ad045a18efe",
   "metadata": {},
   "source": [
    "## Simple computation of the IEM between two example images"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ecfeee0-7574-4a40-a7ff-41bcd9d2f7c0",
   "metadata": {},
   "source": [
    "# For our trained diffusion model, the input images must be of size 256x256.\n",
    "# ref_img = (resize(read_image('./examples/butter_flower.png'), 256).unsqueeze(0).cuda() / 255.) * 2. - 1.\n",
    "# dist_img = (resize(read_image('./examples/butter_flower.fnoise.2.png'), 256).unsqueeze(0).cuda() / 255.) * 2. - 1.\n",
    "ref_img = (resize(read_image('./examples/butter_flower.png'), 256).unsqueeze(0).cuda() / 255.) * 2. - 1.\n",
    "dist_img = (resize(read_image('./examples/butter_flower.fnoise.2.png'), 256).unsqueeze(0).cuda() / 255.) * 2. - 1.\n",
    "\n",
    "num_gamma = 64\n",
    "sigma_min = 1.\n",
    "sigma_max = 1e3\n",
    "iem_type = 'standard'\n",
    "seed = 42\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(iem(ref_img, dist_img, num_gamma=num_gamma, sigma_min=sigma_min, sigma_max=sigma_max, iem_type=iem_type, seed=seed))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c32e86e4-76b0-4088-8093-d01789640459",
   "metadata": {},
   "source": [
    "## Minimize or maximize the IEM between an image and its distorted version while keeping the PSNR fixed"
   ]
  },
  {
   "cell_type": "code",
   "id": "7bf817ad-2fde-4e0d-81a6-6ef41c21ff82",
   "metadata": {},
   "source": [
    "from torch import optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def optimize(diffusion_model, x, target_l2, sigma_min, sigma_max, num_opt_steps, lr=1e-3, minimize=True):\n",
    "    torch.manual_seed(42)\n",
    "    delta = x.clone() + torch.randn_like(x) * 0.01\n",
    "    delta = target_l2 * delta / torch.norm(delta)\n",
    "    delta = delta.clone().detach()\n",
    "    delta.requires_grad_(True)\n",
    "    \n",
    "    opt = optim.Adam([delta], lr=lr)\n",
    "    pbar = tqdm(range(num_opt_steps))\n",
    "    for i in pbar:\n",
    "        opt.zero_grad()\n",
    "        gamma_min = 1 / (sigma_max ** 2)\n",
    "        gamma_max = 1 / (sigma_min ** 2)\n",
    "        u = torch.rand(1).cuda() * (math.log(gamma_max) - math.log(gamma_min)) + math.log(gamma_min)\n",
    "        gamma = u.exp()\n",
    "\n",
    "\n",
    "        sigma = 1 / gamma.sqrt()\n",
    "        noise = sigma.item() * torch.randn_like(x)\n",
    "        y_sigma1 = x + noise\n",
    "        y_sigma2 = (x + delta).clip(-1,1) + noise\n",
    "        with torch.no_grad():\n",
    "            est1 = diffusion_model(y_sigma1, sigma)\n",
    "        est2 = diffusion_model(y_sigma2, sigma)\n",
    "        diff = (x - est1) - ((x + delta).clip(-1,1) - est2)\n",
    "        loss = diff.pow(2).mean()\n",
    "        if not minimize:\n",
    "            loss = - loss\n",
    "        loss = gamma * loss + 10 * ((x + delta).clip(-1,1).detach() - (x + delta)).abs().mean()\n",
    "        loss.backward()\n",
    "        pbar.set_description(f\"loss={loss.item()}\")\n",
    "        opt.step()\n",
    "        with torch.no_grad():\n",
    "            delta /= torch.norm(delta.data)\n",
    "            delta *= target_l2\n",
    "    return delta\n",
    "\n",
    "deltas = []\n",
    "dim = 256 * 256 * 3\n",
    "psnr_targets = [15, 20, 25, 30, 35]\n",
    "def psnr_to_l2(psnr):\n",
    "    return math.sqrt(dim) * 2 * 10 ** (-psnr / 20)\n",
    "l2_targets = [psnr_to_l2(psnr) for psnr in psnr_targets]\n",
    "for l2_target in l2_targets:\n",
    "    delta_min = optimize(iem.diffusion_model, ref_img, l2_target, sigma_min=1e-1, sigma_max=1e3, num_opt_steps=100, lr=5e-3, minimize=True)\n",
    "    delta_max = optimize(iem.diffusion_model, ref_img, l2_target, sigma_min=1e-1, sigma_max=1e3, num_opt_steps=100, lr=5e-3, minimize=False)\n",
    "    deltas.append((delta_min, delta_max))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fcbd9b9e-ed72-49df-b0ea-63d1ce892691",
   "metadata": {},
   "source": [
    "def psnr(x1, x2):\n",
    "    mse = (x1 - x2).pow(2).mean()\n",
    "    return 10 * torch.log10(1 / mse)\n",
    "os.makedirs('./examples_distorted', exist_ok=True)\n",
    "for i, ((delta_min, delta_max), psnr_target) in enumerate(zip(deltas, psnr_targets)):\n",
    "    if i == 0:\n",
    "        save_image(ref_img * 0.5 + 0.5,  os.path.join('./examples_distorted', 'ref_img.png'))\n",
    "    distorted_delta_min = ((ref_img + delta_min).clip(-1, 1)) * 0.5 + 0.5\n",
    "    distorted_delta_max = ((ref_img + delta_max).clip(-1, 1)) * 0.5 + 0.5\n",
    "\n",
    "    print(psnr_target, psnr(distorted_delta_min, ref_img * 0.5 + 0.5), psnr(distorted_delta_max, ref_img * 0.5 + 0.5))\n",
    "    \n",
    "    save_image(distorted_delta_min, os.path.join('./examples_distorted', f'distorted_delta_min_psnr={psnr_target}.png'))\n",
    "    save_image(distorted_delta_max, os.path.join('./examples_distorted', f'distorted_delta_max_psnr={psnr_target}.png'))\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
